# 前言
这是来自北京邮电大学人工智能学院2024219110班苏积烨(学号__2024211856__)的python期末大作业
完成了作业的必做部分，完成了选做部分的ai总结，具体功能和介绍详见后文项目说明，演示视频和ppt在./video/目录下


# 文件结构
    ├── cookies.json
    ├── data/
    ├── data_test/
    ├── demo.py
    ├── note/
    ├── readme.md
    ├── requirement.txt
    └── src/
        ├── process.py
        ├── scraper.py
        └── summarizer.py


# 项目说明
1. 本项目是一个基于python的网络爬虫,用于从小红书爬取用户的笔记信息,并对其进行筛选和总结
2. 项目包含三个主要功能模块:scraper.py,process.py和summarizer.py
3. 目前浏览器的配置信息适用于arm架构macOS上的Chrome浏览器(版本 143.0.7499.193（正式版本） (arm64)),更换测试平台可能需要自行重新配置

## scraper.py
负责登录网站并根据关键词进行笔记的爬取,保存对应的笔记文本和图片到./data/目录下,并将结果保存为json文件

## process.py
负责对爬取到的图片和文本进行复制和筛选,将符合条件的笔记和其中符合条件的文本和图片用相同的格式保存到./note/目录下

## summarizer.py
调用智谱ai,对爬取到的笔记文本进行总结,并将总结结果保存到./note/目录下的summary.txt文件中

## data/
该目录下保存了从网站爬取到的原始数据,下面的每一个子文件夹用笔记的标题命名,其中包含用户的笔记文本(note.txt)和图片
data/目录下的notes_data.json文件保存了所有爬取到的笔记图片和文本url

## note/
该目录下保存了筛选后的笔记数据,格式和data/中的保持一致
note/目录下的summary.txt文件保存了对所有爬取到的笔记文本进行总结的结果


## data_test/
该目录下保存了测试用的原始数据,格式和data/中的保持一致,用于测试process.py模块的功能


# 运行说明
1. 安装依赖:在项目根目录下运行`pip install -r requirement.txt`
2. 配置cookies:将登录网站后的cookies.json文件复制到项目根目录下
3. 对于unix和类unix系统,在项目根目录下提供和start.sh文件,运行`./start.sh`即可启动项目，完成自动的爬取和处理
4. 如果需要单独运行某个模块,请在项目根目录下运行`python src/<module_name>.py`


# 环境要求
    opencv-python
    requests
    selenium
    webdriver_manager

    # 以下为可选项(用于完成ai总结功能)
    ollama
    zai-sdk


# 开发日志
## v_0.1
1. 完成了项目的基本功能,包括登录网站、根据关键词爬取笔记
2. 但是在实际运行中,容易触发反爬机制,导致显示笔记内容为空(不排除笔记本身内容问题导致的限制访问)
## v_0.2
1. 添加了对爬取到的内容进行后处理的功能,包括图片和文本内容的筛选
2. 实际测试目前不触发反爬机制能够正常爬取的内容占比大约为20%,下一版本将着手处理此问题
## v_0.3
1. 通过添加下载等待时间,增加触发反爬后的等待时间,有效提高了能够正常爬取的内容占比
2. 目前爬取内容的成功率在50%左右,后续将继续优化等待时间的逻辑
## v_0.4
1. 利用webdriver_manager自动管理浏览器驱动,避免手动配置
## v_1.0
1. 增加了利用智谱ai对爬取到的文本笔记进行总结的功能
2. 规范统一了各模块的代码规范,改善了可读性
3. 下一版本将尝试增加自动发布的功能


# 待实现的功能
1. [x]~~自动使用cookies.json文件中的cookies登录网站~~
2. [x]~~自动根据关键词进行笔记的爬取,保存对应的笔记文本和图片到./data/目录下,并将结果保存为json文件~~
3. [x]~~对爬取到的图片和文本进行复制和筛选,将符合条件的笔记和其中符合条件的文本和图片保存到./note/目录~~
4. [ ]自动发布功能的实现
5. [x]~~利用ai对爬取到的文本笔记进行总结~~
6. [ ]增加完善ai对于图片的读取和总结功能
7. [x]~~增加对小红书反爬的处理,减少触发反爬机制的概率~~
8. [ ]添加自动完成人机验证的功能

